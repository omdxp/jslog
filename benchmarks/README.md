# jslog Benchmarks

Performance benchmarks comparing `@omdxp/jslog` against popular Node.js logging libraries.

## üìä Latest Results

**[View Full Benchmark Results ‚Üí](./BENCH.md)**

Comprehensive benchmark report including both original and Pino-style benchmarks with detailed performance analysis.

## Benchmark Suites

We provide two comprehensive benchmark suites, all included in a single unified report:

### 1. Original Benchmarks (Benchmark.js)
Traditional benchmarks comparing basic operations:
- Simple string logging
- Complex object logging
- High throughput tests

### 2. Pino-Style Benchmarks (fastbench)
Using Pino's exact benchmark methodology across 7 scenarios:
- ‚úÖ Basic string logging
- ‚úÖ Single object attribute
- ‚úÖ Deep object logging
- ‚úÖ Long string logging (2000 chars)
- ‚úÖ Child logger usage
- ‚úÖ Nested child loggers
- ‚úÖ Multiple arguments

## Benchmarked Libraries

- **jslog** - This library
- **pino** - Fast JSON logger
- **winston** - Versatile logging library
- **bunyan** - JSON logging library
- **log4js** - Log4j inspired logger

## Running Benchmarks

```bash
# Install dependencies
npm install

# Generate comprehensive benchmark report (runs all benchmarks and creates BENCH.md)
npm run bench:report

# Or run original benchmarks individually
npm run bench              # Run all original benchmarks
npm run bench:simple       # Simple string logging
npm run bench:complex      # Complex object logging
npm run bench:throughput   # High throughput test

# Run Pino-style benchmarks individually
cd pino-style
node basic.bench.js
node object.bench.js
node deep-object.bench.js
node long-string.bench.js
node child.bench.js
node child-child.bench.js
node multi-arg.bench.js
```

## Key Findings üîç

### Original Benchmarks Results

**jslog dominates with 100% win rate:**
- **Simple String Logging**: 254.9% faster than Pino
- **Complex Object Logging**: 112.1% faster than Pino
- **High Throughput Test**: 6.6% faster than Pino

### Pino-Style Benchmarks Results

**jslog wins in 2/7 scenarios:**

#### Where jslog Wins ü•á
- **Basic String Logging**: 2.3% faster than Pino
- **Deep Object Logging**: 58.4% faster than Pino
  - Best-in-class complex object serialization

#### Where jslog is Competitive ü•à
- **Single Object Attribute**: 6.7% slower than Pino (nearly tied)
- **Child Logger**: 9.4% slower than Pino
- **Long String**: 11.9% slower than Pino
- **Nested Child Logger**: 17.2% slower than Pino

#### Areas for Improvement üéØ
- **Multiple Arguments**: 42.0% slower than Pino
  - Working on optimizing multi-attribute logging

## Benchmark Types

### 1. Simple String Logging
Tests basic string message logging performance.

```javascript
logger.info('Hello, world!');
```

### 2. Complex Object Logging
Tests logging with multiple attributes and different data types.

```javascript
logger.info('User action',
  String('userId', 'user-12345'),
  String('action', 'purchase'),
  Int('amount', 99),
  Float64('price', 99.99),
  Bool('verified', true),
  String('ip', '192.168.1.1')
);
```

### 3. High Throughput
Tests sustained performance with 100,000 iterations.

```javascript
for (let i = 0; i < 100000; i++) {
  logger.info('Request processed',
    String('requestId', `req-${i}`),
    Int('iteration', i)
  );
}
```

## Interpreting Results

- **ops/sec** - Operations per second (higher is better)
- **logs/sec** - Log entries per second (higher is better)
- **ms** - Milliseconds for fastbench tests (lower is better)
- **Relative Performance** - Percentage difference from fastest
- **Rank** - Position compared to other libraries (ü•áü•àü•â)

All benchmarks output to `/dev/null` to minimize I/O overhead and focus on pure logging performance.

## System Info

Results may vary based on:
- CPU speed and cores
- Node.js version
- Operating system
- Available memory
- Disk I/O speed (when logging to files)

## Contributing

To add more benchmarks or libraries:

1. Add the library to `package.json`
2. Create a new benchmark file (either in root or `pino-style/` directory)
3. Update the `generate-report.js` script if needed
4. Run `npm run bench:report` to regenerate the report
5. Update this README with any new findings

## Report Generation

The unified benchmark report is generated by:
```bash
npm run bench:report
```

This runs all benchmarks (original + Pino-style) and generates a comprehensive `BENCH.md` file with:
- System information
- All benchmark results
- Performance comparisons
- Summary statistics
- Key highlights

## License

MIT

